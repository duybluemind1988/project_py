{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arena For Python\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "\n",
    "train = dx.datasets.load_apartments()\n",
    "test = dx.datasets.load_apartments_test()\n",
    "\n",
    "X_train = train.drop(columns='m2_price')\n",
    "y_train = train[\"m2_price\"]\n",
    "\n",
    "X_test= test.drop(columns='m2_price')\n",
    "y_test = test[\"m2_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>construction_year</th>\n",
       "      <th>surface</th>\n",
       "      <th>floor</th>\n",
       "      <th>no_rooms</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1953</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Srodmiescie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992</td>\n",
       "      <td>143</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Bielany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1937</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Praga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Ochota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1992</td>\n",
       "      <td>144</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Mokotow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1921</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Srodmiescie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1921</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Bemowo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1980</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Bemowo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1942</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Zoliborz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1992</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Mokotow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      construction_year  surface  floor  no_rooms     district\n",
       "1                  1953       25      3         1  Srodmiescie\n",
       "2                  1992      143      9         5      Bielany\n",
       "3                  1937       56      1         2        Praga\n",
       "4                  1995       93      7         3       Ochota\n",
       "5                  1992      144      6         5      Mokotow\n",
       "...                 ...      ...    ...       ...          ...\n",
       "996                1921       44      2         2  Srodmiescie\n",
       "997                1921       48     10         2       Bemowo\n",
       "998                1980       85      3         3       Bemowo\n",
       "999                1942       36      7         1     Zoliborz\n",
       "1000               1992      112      6         5      Mokotow\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       5897\n",
       "2       1818\n",
       "3       3643\n",
       "4       3517\n",
       "5       3013\n",
       "        ... \n",
       "996     6355\n",
       "997     3422\n",
       "998     3098\n",
       "999     4192\n",
       "1000    3327\n",
       "Name: m2_price, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "numerical_features = X_train.select_dtypes(exclude=[object]).columns\n",
    "numerical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_features = X_train.select_dtypes(include=[object]).columns\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['construction_year', 'surface', 'floor', 'no_rooms'], dtype='object')),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['district'], dtype='object'))])),\n",
       "                ('model', DecisionTreeRegressor())])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model_elastic_net = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', ElasticNet())\n",
    "    ]\n",
    ")\n",
    "model_elastic_net.fit(X=X_train, y=y_train)\n",
    "model_decision_tree = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', DecisionTreeRegressor())\n",
    "    ]\n",
    ")\n",
    "model_decision_tree.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dalex Explainer for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 9000 rows 5 cols\n",
      "  -> target variable   : Argument 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 9000 values\n",
      "  -> model_class       : sklearn.linear_model._coordinate_descent.ElasticNet (default)\n",
      "  -> label             : not specified, model's class short name is taken instead (default)\n",
      "  -> predict function  : <function yhat_default at 0x7f20f25841e0> will be used (default)\n",
      "  -> predict function  : accepts only pandas.DataFrame, numpy.ndarray causes problems\n",
      "  -> predicted values  : min = 2.46e+03, mean = 3.5e+03, max = 4.66e+03\n",
      "  -> model type        : regression will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -9.47e+02, mean = 11.4, max = 2.16e+03\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 9000 rows 5 cols\n",
      "  -> target variable   : Argument 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 9000 values\n",
      "  -> model_class       : sklearn.tree._classes.DecisionTreeRegressor (default)\n",
      "  -> label             : not specified, model's class short name is taken instead (default)\n",
      "  -> predict function  : <function yhat_default at 0x7f20f25841e0> will be used (default)\n",
      "  -> predict function  : accepts only pandas.DataFrame, numpy.ndarray causes problems\n",
      "  -> predicted values  : min = 1.61e+03, mean = 3.51e+03, max = 6.6e+03\n",
      "  -> model type        : regression will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.28e+03, mean = 5.42, max = 1.19e+03\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    }
   ],
   "source": [
    "exp_elastic_net = dx.Explainer(model_elastic_net, data=X_test, y=y_test)\n",
    "exp_decision_tree = dx.Explainer(model_decision_tree, data=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arena features\n",
    "### Live mode using all available observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arena.drwhy.ai/?data=http://127.0.0.1:9294/\n"
     ]
    }
   ],
   "source": [
    "# create empty Arena\n",
    "arena=dx.Arena()\n",
    "# push created explainer\n",
    "arena.push_model(exp_elastic_net)\n",
    "# push whole test dataset (including target column)\n",
    "arena.push_observations(test)\n",
    "# run server on port 9294\n",
    "arena.run_server(port=9294)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Server is auto updating. You can add second model when it is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arena.push_model(exp_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can stop the server using this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arena.stop_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static mode using subset of observations\n",
    "You create Arena exacly the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty Arena\n",
    "arena=dx.Arena()\n",
    "# push created explainers\n",
    "arena.push_model(exp_elastic_net)\n",
    "arena.push_model(exp_decision_tree)\n",
    "# push first 3 rows of tasting dataset\n",
    "arena.push_observations(test.iloc[0:3])\n",
    "# save arena to file\n",
    "arena.save(\"data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can auto upload this data source to GitHub Gist service. By default OAuth is used, but you can provide your Personal Access Token using `token` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://arena.drwhy.ai/?data=https://gist.githubusercontent.com/piotrpiatyszek/5cea41eba9982268a25fda3934c1221a/raw/bfb3c8daa677c6d3a56fe883cf62756e0fc163ff/datasource.json'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arena.upload(open_browser=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart options\n",
    "Options are described for each plot in official Arena's Guide  \n",
    "https://arena.drwhy.ai/docs/guide/observation-level  \n",
    "https://arena.drwhy.ai/docs/guide/dataset-level  \n",
    "https://arena.drwhy.ai/docs/guide/fairness  \n",
    "https://arena.drwhy.ai/docs/guide/model-performance  \n",
    "https://arena.drwhy.ai/docs/guide/eda-charts  \n",
    "Short description are available using `print_options` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arena.drwhy.ai/?data=http://127.0.0.1:9294/\n",
      "\n",
      "\u001b[1mSHAPValues\u001b[0m\n",
      "---------------------------------\n",
      "B: 10   #Number of random paths\n",
      "\n",
      "\u001b[1mFeatureImportance\u001b[0m\n",
      "---------------------------------\n",
      "N: None   #Number of observations to use. None for all.\n",
      "B: 10   #Number of permutation rounds to perform each variable\n",
      "\n",
      "\u001b[1mPartialDependence\u001b[0m\n",
      "---------------------------------\n",
      "grid_type: quantile   #grid type \"quantile\" or \"uniform\"\n",
      "grid_points: 101   #Maximum number of points for profile\n",
      "N: 500   #Number of observations to use. None for all.\n",
      "\n",
      "\u001b[1mAccumulatedDependence\u001b[0m\n",
      "---------------------------------\n",
      "grid_type: quantile   #grid type \"quantile\" or \"uniform\"\n",
      "grid_points: 101   #Maximum number of points for profile\n",
      "N: 500   #Number of observations to use. None for all.\n",
      "\n",
      "\u001b[1mCeterisParibus\u001b[0m\n",
      "---------------------------------\n",
      "grid_points: 101   #Maximum number of points for profile\n",
      "grid_type: quantile   #grid type \"quantile\" or \"uniform\"\n",
      "\n",
      "\u001b[1mBreakdown\u001b[0m\n",
      "---------------------------------\n",
      "\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "---------------------------------\n",
      "\n",
      "\u001b[1mROC\u001b[0m\n",
      "---------------------------------\n",
      "grid_points: 101   #Maximum number of points for ROC curve\n"
     ]
    }
   ],
   "source": [
    "arena=dx.Arena()\n",
    "arena.push_model(exp_decision_tree)\n",
    "arena.push_observations(test)\n",
    "arena.run_server(port=9294)\n",
    "\n",
    "arena.print_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily change options for charts and dashboard will be automaticly refreshed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart-specific\n",
    "arena.set_option('CeterisParibus', 'grid_type', 'uniform')\n",
    "# For all charts\n",
    "arena.set_option(None, 'grid_points', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mSHAPValues\u001b[0m\n",
      "---------------------------------\n",
      "B: 10   #Number of random paths\n",
      "\n",
      "\u001b[1mFeatureImportance\u001b[0m\n",
      "---------------------------------\n",
      "N: None   #Number of observations to use. None for all.\n",
      "B: 10   #Number of permutation rounds to perform each variable\n",
      "\n",
      "\u001b[1mPartialDependence\u001b[0m\n",
      "---------------------------------\n",
      "grid_type: quantile   #grid type \"quantile\" or \"uniform\"\n",
      "grid_points: 200   #Maximum number of points for profile\n",
      "N: 500   #Number of observations to use. None for all.\n",
      "\n",
      "\u001b[1mAccumulatedDependence\u001b[0m\n",
      "---------------------------------\n",
      "grid_type: quantile   #grid type \"quantile\" or \"uniform\"\n",
      "grid_points: 200   #Maximum number of points for profile\n",
      "N: 500   #Number of observations to use. None for all.\n",
      "\n",
      "\u001b[1mCeterisParibus\u001b[0m\n",
      "---------------------------------\n",
      "grid_points: 200   #Maximum number of points for profile\n",
      "grid_type: uniform   #grid type \"quantile\" or \"uniform\"\n",
      "\n",
      "\u001b[1mBreakdown\u001b[0m\n",
      "---------------------------------\n",
      "\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "---------------------------------\n",
      "\n",
      "\u001b[1mROC\u001b[0m\n",
      "---------------------------------\n",
      "grid_points: 200   #Maximum number of points for ROC curve\n"
     ]
    }
   ],
   "source": [
    "arena.print_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache [Advanced]\n",
    "Cache contains already generated charts. In live mode there are those charts, that user have opened.\n",
    "In static mode cache contains all charts if precalculate=True or save method was called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# default way with precalculate=False\n",
    "arena=dx.Arena()\n",
    "arena.push_model(exp_elastic_net)\n",
    "print(len(arena.cache))\n",
    "arena.save('data.json')\n",
    "print(len(arena.cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# default way with precalculate=True\n",
    "arena=dx.Arena(precalculate=True)\n",
    "arena.push_model(exp_elastic_net)\n",
    "print(len(arena.cache))\n",
    "arena.push_model(exp_decision_tree)\n",
    "print(len(arena.cache))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling and clearing cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "0\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(arena.cache))\n",
    "\n",
    "arena.clear_cache()\n",
    "print(len(arena.cache))\n",
    "\n",
    "arena.fill_cache()\n",
    "print(len(arena.cache))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Options\n",
    "Changing options removes specified charts for cache. If precalculate is True, then charts are generated again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# precalculate is enabled\n",
    "print(len(arena.cache))\n",
    "arena.set_option('FeatureImportance', 'B', 5)\n",
    "print(len(arena.cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "arena.precalculate = False\n",
    "print(len(arena.cache))\n",
    "arena.set_option('FeatureImportance', 'B', 5)\n",
    "print(len(arena.cache))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
