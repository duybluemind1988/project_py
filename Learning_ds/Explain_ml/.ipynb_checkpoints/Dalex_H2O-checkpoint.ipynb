{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare various models with dalex ft. h2o, autokeras, catboost, lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Insurance Cross Sell Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import autokeras as ak\n",
    "import kerastuner as kt\n",
    "import h2o\n",
    "import catboost\n",
    "import lightgbm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session info\n",
    "pkg_dict = {}\n",
    "for pkg in [dx, pd, np, sklearn, tf, ak, kt, h2o, catboost, lightgbm]:\n",
    "    pkg_dict[str.split(str(pkg))[1].replace(\"'\", \"\")] = pkg.__version__\n",
    "pd.DataFrame(pkg_dict, index=[\"version\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data (train.csv) from: https://www.kaggle.com/anmolkumar/health-insurance-cross-sell-prediction?select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 381109 entries, 0 to 381108\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    381109 non-null  int64  \n",
      " 1   Gender                381109 non-null  object \n",
      " 2   Age                   381109 non-null  int64  \n",
      " 3   Driving_License       381109 non-null  int64  \n",
      " 4   Region_Code           381109 non-null  float64\n",
      " 5   Previously_Insured    381109 non-null  int64  \n",
      " 6   Vehicle_Age           381109 non-null  object \n",
      " 7   Vehicle_Damage        381109 non-null  object \n",
      " 8   Annual_Premium        381109 non-null  float64\n",
      " 9   Policy_Sales_Channel  381109 non-null  float64\n",
      " 10  Vintage               381109 non-null  int64  \n",
      " 11  Response              381109 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(3)\n",
      "memory usage: 34.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40454.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>33536.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38294.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>28619.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>27496.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0   1    Male   44                1         28.0                   0   \n",
       "1   2    Male   76                1          3.0                   0   \n",
       "2   3    Male   47                1         28.0                   0   \n",
       "3   4    Male   21                1         11.0                   1   \n",
       "4   5  Female   29                1         41.0                   1   \n",
       "\n",
       "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n",
       "0   > 2 Years            Yes         40454.0                  26.0      217   \n",
       "1    1-2 Year             No         33536.0                  26.0      183   \n",
       "2   > 2 Years            Yes         38294.0                  26.0       27   \n",
       "3    < 1 Year             No         28619.0                 152.0      203   \n",
       "4    < 1 Year             No         27496.0                 152.0       39   \n",
       "\n",
       "   Response  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 380k observations, 11 variables and binary target. For the purpose of this comparison, let's use 10% of the data.\n",
    "\n",
    "Clean data:\n",
    "\n",
    "remove id, Policy_Sales_Channel, Region_Code\n",
    "\n",
    "convert Vehicle_Age to integer\n",
    "\n",
    "convert Gender, Vehicle_Damage to binary\n",
    "\n",
    "investigate Driving_License, Annual_Premium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data, _ = train_test_split(data, train_size=0.1, random_state=1, stratify=data.Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "data.drop([\"id\", \"Region_Code\", \"Policy_Sales_Channel\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert three columns\n",
    "print(data.Vehicle_Age.unique())\n",
    "data.replace({'Gender': [\"Male\", \"Female\"], 'Vehicle_Damage': [\"Yes\", \"No\"], 'Vehicle_Age': data.Vehicle_Age.unique()},\n",
    "             {'Gender': [1, 0], 'Vehicle_Damage': [1, 0], 'Vehicle_Age': [2, 1, 0]},\n",
    "            inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about Driving License in selling the vehicle insurance?\n",
    "print(data.Driving_License.mean())\n",
    "\n",
    "# 5% people bought the vehicle insurance without the Driving License\n",
    "print(data.Response[data.Driving_License==0].mean())\n",
    "\n",
    "# let's remove this variable for the clarity\n",
    "# in the model we could assign: IF Driving_License == 0 THEN Response = 0\n",
    "data.drop(\"Driving_License\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about the distribution of Annual_Premium?\n",
    "import matplotlib.pyplot as plt\n",
    "_ = plt.hist(data.Annual_Premium, bins='auto', log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where is the peek?\n",
    "print(data.Annual_Premium.min())\n",
    "\n",
    "# a lot of the same values\n",
    "print((data.Annual_Premium==data.Annual_Premium.min()).sum())\n",
    "\n",
    "# some very big values (0.2% above 100k)\n",
    "print((data.Annual_Premium>100000).sum() / data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a variable indicating the baseline, and move the annual premium\n",
    "data = data.assign(\n",
    "    Annual_Premium_Baseline=lambda x: (x.Annual_Premium==data.Annual_Premium.min()).astype(int),\n",
    "    Annual_Premium=data.Annual_Premium-data.Annual_Premium.min()\n",
    ")\n",
    "\n",
    "# for the sake of this comparison, let's remove heavy outliers as well\n",
    "data = data[data.Annual_Premium<100000-2630]\n",
    "_ = plt.hist(data.Annual_Premium, bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Response.mean() # uneven target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.drop(\"Response\", axis=1), data.Response\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_baseline = lightgbm.LGBMClassifier(boosting_type=\"dart\", n_estimators=1000, is_unbalance=True)\n",
    "model_baseline.fit(X_train, y_train)\n",
    "exp_baseline = dx.Explainer(model_baseline, X_test, y_test, verbose=False, label=\"lgbm_dart\")\n",
    "exp_baseline.model_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = h2o.init(nthreads=-1, max_mem_size=16)\n",
    "h2o.no_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = h2o.H2OFrame(pd.concat([X_train, y_train], axis=1))\n",
    "df.Response = df['Response'].asfactor()\n",
    "model_h2o = h2o.estimators.H2ORandomForestEstimator(ntrees=1000,\n",
    "                                                    nfolds=3,\n",
    "                                                    balance_classes=True,\n",
    "                                                    seed=1)\n",
    "model_h2o.train(x=X_train.columns.to_list(),\n",
    "                y=\"Response\",\n",
    "                training_frame=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_h2o = dx.Explainer(model_h2o, h2o.H2OFrame(X_test), y_test,\n",
    "                       label=\"h2o_rf\", model_type='classification', verbose=False)\n",
    "exp_h2o.model_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "weights = dict(enumerate(class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                           classes=y_train.unique(),\n",
    "                                                           y=y_train)))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "model_autokeras = ak.StructuredDataClassifier(\n",
    "    max_trials=5,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ],\n",
    "    num_classes= 2,\n",
    "    objective=kt.Objective(\"auc\", direction=\"max\"),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "    tuner=\"random\",\n",
    "    seed=1, overwrite=True\n",
    ")\n",
    "\n",
    "model_autokeras.fit(X_train, y_train, validation_split=0.25, class_weight=weights, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = model_autokeras.export_model()\n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_keras = dx.Explainer(model=model_keras, data=X_test, y=y_test,\n",
    "                         label=\"autokeras\", model_type=\"classification\", verbose=False)\n",
    "exp_keras.model_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "weights = dict(enumerate(class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                           classes=y_train.unique(),\n",
    "                                                           y=y_train)))\n",
    "y_weights = y_train.replace(list(weights.keys()), list(weights.values()))\n",
    "y_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_train = catboost.Pool(X_train, y_train,\n",
    "                           weight=y_weights)\n",
    "model_catboost = catboost.CatBoostClassifier(iterations=2000)\n",
    "model_catboost.fit(pool_train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_catboost = dx.Explainer(model_catboost, X_test, y_test, verbose=False, label=\"catboost\")\n",
    "exp_catboost.model_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Comparison with dalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
